{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoak/Deep-Learning-Projects/blob/main/Batching_and_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDn05F_vWwdJ"
      },
      "source": [
        "### Lab 3.1: Batching and Regularization\n",
        "\n",
        "In this lab you will learn how to set up a dataset to be processed in batches, rather than processing the entire dataset in each training iteration, and explore neural network regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNQlO3P6WwdK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sklearn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TkP_Rr9WwdL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn ucimlrepo mlxtend\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = adult.data.features\n",
        "y = adult.data.targets\n",
        "\n",
        "# metadata\n",
        "print(adult.metadata)\n",
        "\n",
        "# variable information\n",
        "print(adult.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53lMqw2TWwdM"
      },
      "outputs": [],
      "source": [
        "X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw9_RsidWwdN"
      },
      "outputs": [],
      "source": [
        "y = y['income'].map({'<=50K':0,'<=50K.':0,'>50K':1,'>50K.':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMxF-R5aWwdN"
      },
      "outputs": [],
      "source": [
        "X = X[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfbtbqgTWwdO"
      },
      "outputs": [],
      "source": [
        "y = y.values\n",
        "X = X.values.astype('float64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "027xJrV2WwdO"
      },
      "source": [
        "To make the learning algorithm work more smoothly, we we will subtract the mean of each feature.\n",
        "\n",
        "Here `np.mean` calculates a mean, and `axis=0` tells NumPy to calculate the mean over the rows (calculate the mean of each column)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjCJTXKHWwdO"
      },
      "outputs": [],
      "source": [
        "X -= np.mean(X,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bvInWGWwdP"
      },
      "source": [
        "Now we will convert our `X` and `y` arrays to torch Tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qSD56u4WwdP"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X).float()\n",
        "y = torch.tensor(y).long()\n",
        "\n",
        "bad = X.isna().any(axis=1)\n",
        "X = X[~bad]\n",
        "y = y[~bad]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXBrbujSWwdQ"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "1. Divide the data into train and test splits.\n",
        "2. Create a neural network for this dataset.\n",
        "3. Use `TensorDataset` and `DataLoader` to batch the dataset during training.  \n",
        "4. Use `weight_decay` parameter to `optim.SGD` to introduce L2 regularization during training. Evaluate the effect of regularization on test set accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(X, y)"
      ],
      "metadata": {
        "id": "onSu6o2paIGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqY-e2cWwdQ"
      },
      "outputs": [],
      "source": [
        "# numba 1\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size= .1, train_size= .9, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numba 2\n",
        "multilayer_model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(6,100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100,2),\n",
        "    # two inputs, three outputs\n",
        ")\n",
        "\n",
        "lr = 1e-2\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(multilayer_model.parameters(), lr=lr, weight_decay= 0.001)"
      ],
      "metadata": {
        "id": "YrtDt5CHYxt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numba 3 MIGHT NEED TO DO THE GRADIENT INITIALIZATION THING FROM LAB 3.1\n",
        "batch_size = 32 # 32 in homework\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(10):  # Example: 3 epochs\n",
        "  print(f\"Epoch {epoch + 1}\")\n",
        "  for batch_idx, (batch_X, batch_y) in enumerate(dataloader):\n",
        "    opt.zero_grad() # zero out the gradients\n",
        "    z = multilayer_model(X) # compute z values\n",
        "    loss = loss_fn(z,y) # compute loss\n",
        "    loss.backward() # compute gradients\n",
        "    opt.step()\n",
        "  print(f'epoch {epoch}: loss is {loss.item()}')\n"
      ],
      "metadata": {
        "id": "a5auKAHjZjHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "batch_size = 32\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Iji23D90l4uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numba 4\n",
        "multilayer_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for testing\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = multilayer_model(batch_X)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "YbzUv28IZkU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response:** My loss is being outputed as nan so this is speculative. The result of the weight decay in regularization will reduce variance in the fit to the training data. So, this should make the model more general and increase the test accuracy on the testing data."
      ],
      "metadata": {
        "id": "ZuZ52bWmmed8"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}