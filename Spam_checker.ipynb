{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOp3dUn5P91ME3v+nEL5UC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoak/Deep-Learning-Projects/blob/main/Spam_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task in this lab is to set up and train a neural network on any dataset of your choosing.   Look at UCI ML Repo and Kaggle to find datasets, for example.  \n",
        "\n",
        "Train a neural network on the dataset without any regularization or other special techniques to get a baseline train and test error.  Then see how much you can improve the network's test error through techniques learned in class like regularization, different optimizers, batch normalization, etc."
      ],
      "metadata": {
        "id": "GDKDLnl1EHEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import data\n",
        "* Format data\n",
        "* Create test and training sets\n",
        "* Train model\n",
        "\n",
        "* Optomize later"
      ],
      "metadata": {
        "id": "LEawtU42D1kj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgMuKB2LDyfO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import sklearn\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "data = files.upload()"
      ],
      "metadata": {
        "id": "oOAquoeTE1r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0),"
      ],
      "metadata": {
        "id": "d89VvJpLLl8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "names = files.upload()\n",
        "filename = next(iter(names))"
      ],
      "metadata": {
        "id": "bH4jxxGxUx7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_string = \"1, 0.    | spam, non-spam classes\"\n",
        "names_list = []\n",
        "with open(filename, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            if stop_string in line:\n",
        "                break\n",
        "        line = file.readline()\n",
        "        for line in file:\n",
        "            title = line.strip().split(\":\")[0]\n",
        "            names_list.append(title)\n",
        "print(names_list)"
      ],
      "metadata": {
        "id": "ZaJHJ1qvWGx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(names)"
      ],
      "metadata": {
        "id": "TSJ4Y64sVAT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spambase.data', header=None, names = names_list)\n",
        "print(df.shape)\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "sPPt1mWtKD9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "33IpS2KWZx3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKE BATCH SIZE 57\n",
        "X_values = df.iloc[:, :-1].values  # Features (all columns except last)\n",
        "X_torch = torch.tensor(X_values).float()\n",
        "y = df.iloc[:, -1].values   # Target (last column)\n",
        "y_torch = torch.tensor(y).long()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_torch, y_torch, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Split dataset: 80% training, 20% testing\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(X_torch, y_torch, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Second split: Validation (10%) and Test (10%) from Temp\n",
        "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "gazqXo2gMX5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_torch = torch.tensor(X_train).float()\n",
        "# X_test_torch = torch.tensor(X_test).float()\n",
        "# y_train_torch = torch.tensor(y_train).long()\n",
        "# y_test_torch = torch.tensor(y_test).long()\n",
        "# print(X_train.shape)\n",
        "# print(y.shape)"
      ],
      "metadata": {
        "id": "zgVqvKNtZ1aM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "improved_model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(56,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,2),\n",
        ")"
      ],
      "metadata": {
        "id": "9Odtk_dGaVe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(56,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,100),\n",
        "    torch.nn.SiLU(),\n",
        "    torch.nn.Linear(100,2),\n",
        ")"
      ],
      "metadata": {
        "id": "gxizvlfisTJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "lr=1e-2"
      ],
      "metadata": {
        "id": "D4t-Ybr0bIeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader for training data\n",
        "dataset = TensorDataset(X_train, y_train)\n",
        "batch_size = 112\n",
        "trainloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "_ZawGNBxagvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader for validation data\n",
        "dataset = TensorDataset(X_val, y_val)\n",
        "batch_size = 112\n",
        "valloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "AB-CMk8Ju8Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader for test data\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "batch_size = 112\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "P3EL2PjawkPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = float(\"inf\")\n",
        "        self.counter = 0\n",
        "        self.stopped_epoch = None\n",
        "\n",
        "    def check_stop(self, val_loss, epoch):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0  # Reset counter if loss improves\n",
        "        else:\n",
        "            self.counter += 1  # Increment counter if loss does not improve\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            self.stopped_epoch = epoch\n",
        "            return True  # Signal to stop training\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "oC8roWEByDpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_train_model(model, X_train, y_train, loss_func, opt, lr, epochs):\n",
        "  for epoch in range(epochs):\n",
        "      opt.zero_grad() # zero out the gradients\n",
        "      z = model(X_train) # compute z values\n",
        "      loss = loss_fn(z,y_train) # compute loss\n",
        "      loss.backward() # compute gradients\n",
        "      opt.step() # apply gradients\n",
        "      print(f'epoch {epoch}: loss is {loss.item()}')"
      ],
      "metadata": {
        "id": "buqEBqxln9F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=100)"
      ],
      "metadata": {
        "id": "g_MyJyn1vqOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR TRAINING MODELS\n",
        "def train_model(model, dataloader, loss_func, opt, lr, epochs):\n",
        "  train_mses = []\n",
        "  test_mses = []\n",
        "  best_test_mse = np.inf\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      model.train()\n",
        "      for batch_idx, (batch_X, batch_y) in enumerate(dataloader):\n",
        "        opt.zero_grad() # zero out the gradients\n",
        "        z = model(batch_X) # compute z values\n",
        "        loss = loss_fn(z,batch_y) # compute loss\n",
        "        loss.backward() # compute gradients\n",
        "        opt.step() # apply gradients\n",
        "\n",
        "\n",
        "        train_mses.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        pred = model(X_test)\n",
        "        test_mse = loss_fn(pred,y_test).item()\n",
        "\n",
        "        if test_mse < best_test_mse:\n",
        "          best_test_mse = test_mse\n",
        "          torch.save(model.state_dict(), 'best.ckpt')\n",
        "\n",
        "        test_mses.append(test_mse)\n",
        "      print(f'epoch {epoch}: loss is {loss.item()}')\n",
        "\n",
        "  model.load_state_dict(torch.load('best.ckpt', weights_only=True))\n",
        "\n",
        "  model.eval()\n",
        "  pred = model(X_train)\n",
        "  best_train_mse = loss_fn(pred,y_train).item()\n",
        "\n",
        "  pred = model(X_test)\n",
        "  best_test_mse = loss_fn(pred,y_test).item()\n",
        "\n",
        "  return train_mses, test_mses, best_train_mse, best_test_mse"
      ],
      "metadata": {
        "id": "p3Pd0OfAapIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR TESTING MODELS with test data\n",
        "def model_accuracy(model, dataloader):\n",
        "\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  count = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch_X, batch_y in dataloader:\n",
        "          outputs = model(batch_X)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total += batch_y.size(0)\n",
        "          correct += (predicted == batch_y).sum().item()\n",
        "          temp = correct/total\n",
        "          print(f'epoch {count}: Accuracy: {temp}')\n",
        "          count += 1\n",
        "\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "c534liLpa1OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic model using SGD\n",
        "opt = torch.optim.SGD(basic_model.parameters(), lr=lr)\n",
        "basic_train_model(basic_model, X_train, y_train, loss_fn, opt, lr, epochs=200)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0SbtY6GDnDal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy calculation for basic network\n",
        "y_pred = basic_model(X_test)\n",
        "num_pred = y_pred.size(dim=0)\n",
        "max_val, max_idx = torch.max(y_pred, dim = 1)\n",
        "\n",
        "# Test Error\n",
        "total = 0\n",
        "for i in range(num_pred):\n",
        "  if max_idx[i] == y_test[i]:\n",
        "    total += 1\n",
        "\n",
        "accuracy = total/num_pred\n",
        "print(f'Accuracy of Torch NN on test data: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "FYDQ4aR2sHxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training error calculation for basic network\n",
        "y_pred = basic_model(X_train)\n",
        "num_pred = y_pred.size(dim=0)\n",
        "max_val, max_idx = torch.max(y_pred, dim = 1)\n",
        "\n",
        "# Training Error\n",
        "total = 0\n",
        "for i in range(num_pred):\n",
        "  if max_idx[i] == y_train[i]:\n",
        "    total += 1\n",
        "accuracy = total/num_pred\n",
        "error = 1- accuracy\n",
        "print(f'Training error of Torch NN on training data: {error:.4f}')"
      ],
      "metadata": {
        "id": "N7u_n-KEsK0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Adam\n",
        "opt = torch.optim.Adam(improved_model.parameters(), lr=lr, betas =(.9, .999), weight_decay= 0.001)\n",
        "train_mses, test_mses, best_train_mse, best_test_mse = train_model(improved_model, trainloader, loss_fn, opt, lr, epochs = 42)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kJqanvQIhrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test accuracy\n",
        "nn_accuracy = model_accuracy(improved_model, testloader)\n",
        "print(f'Accuracy of Torch NN: {nn_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "R07RN_VXlGQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training accuracy\n",
        "nn_accuracy_train = model_accuracy(improved_model, trainloader)\n",
        "train_error = 1- nn_accuracy_train\n",
        "print(f'Training error of Torch NN: {train_error:.4f}')"
      ],
      "metadata": {
        "id": "V5HjCq_Xrx7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_plot(train_mses,test_mses):\n",
        "  plt.plot(train_mses)\n",
        "  plt.plot(test_mses)\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('MSE')\n",
        "  plt.legend(['Train','Test'])"
      ],
      "metadata": {
        "id": "z0Iqzxb_rErf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "eYfPKuMfrFoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "EeycnsGvrwdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "make_plot(train_mses,test_mses)\n",
        "print(f'# parameters: {count_parameters(improved_model)}')\n",
        "print(f'best train loss:{best_train_mse}')\n",
        "print(f'best test loss:{best_test_mse}')"
      ],
      "metadata": {
        "id": "apr7poQYrJCd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}