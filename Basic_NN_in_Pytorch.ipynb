{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoak/Deep-Learning-Projects/blob/main/Basic_NN_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fde2BCkRNjA0"
      },
      "source": [
        "### Lab 3.1: Basic Neural Network in PyTorch\n",
        "\n",
        "Let's create a linear classifier one more time, but using PyTorch's automatic differentiation and optimization algorithms.  Then you will extend the perceptron into a multi-layer perceptron (MLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pxsAC_xNjA4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cAfxowINjA5"
      },
      "source": [
        "We need to explicitly tell PyTorch when creating a tensor that we are interested in later computing its gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRXzqlNDNjA5"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor(5.,requires_grad=True)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyQD8l9xNjA6"
      },
      "outputs": [],
      "source": [
        "b = torch.tensor(6.,requires_grad=True)\n",
        "c = 2*a+3*b\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArTyvfaaNjA7"
      },
      "source": [
        "To extract the gradients, we first need to call `backward()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUT4smvANjA7"
      },
      "outputs": [],
      "source": [
        "c.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlxpg7JLNjA7"
      },
      "source": [
        "Now to get the gradient of any variable with respect to `c`, we simply access the `grad` attribute of that variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxXSXsduNjA7"
      },
      "outputs": [],
      "source": [
        "a.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7njiN7nNjA8"
      },
      "outputs": [],
      "source": [
        "b.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSiT8Oz6NjA9"
      },
      "source": [
        "Let's load and format the Palmer penguins dataset for multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDyv2-HYNjA9"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn palmerpenguins mlxtend\n",
        "from palmerpenguins import load_penguins\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9J_CDDONjA-"
      },
      "outputs": [],
      "source": [
        "df = load_penguins()\n",
        "\n",
        "# drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# get two features\n",
        "X = df[['flipper_length_mm','bill_length_mm']].values\n",
        "\n",
        "# convert species labels to integers\n",
        "y = df['species'].map({'Adelie':0,'Chinstrap':1,'Gentoo':2}).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbU7IZuhNjA-"
      },
      "source": [
        "To make the learning algorithm work more smoothly, we we will subtract the mean of each feature.\n",
        "\n",
        "Here `np.mean` calculates a mean, and `axis=0` tells NumPy to calculate the mean over the rows (calculate the mean of each column)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awcCn0ekNjA-"
      },
      "outputs": [],
      "source": [
        "X -= np.mean(X,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzFysz58NjA-"
      },
      "source": [
        "Now we will convert our `X` and `y` arrays to torch Tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsK0kQu6NjA_"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X).float()\n",
        "y = torch.tensor(y).long()\n",
        "print(X.shape)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UXArqKhNjA_"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZfUkgffNjBA"
      },
      "source": [
        "The `torch.nn.Sequential` class creates a feed-forward network from a list of `nn.Module` objects.  Here we provide a single `nn.Linear` class which performs an affine transformation ($Wx+b$) so that we will have a linear classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X0s7k74NjBA"
      },
      "outputs": [],
      "source": [
        "linear_model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2,3),\n",
        "    # two inputs, three outputs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZQ8akHlNjBB"
      },
      "source": [
        "Now we create a cross-entropy loss function object and a stochastic gradient descent (SGD) optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWr6NXdeNjBB"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTRLnOgPNjBB"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "opt = torch.optim.SGD(linear_model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uptw1sdlNjBB"
      },
      "source": [
        "Finally we can iteratively optimize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "S6UyVlnrNjBB"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    opt.zero_grad() # zero out the gradients\n",
        "\n",
        "    z = linear_model(X) # compute z values\n",
        "    loss = loss_fn(z,y) # compute loss\n",
        "\n",
        "    loss.backward() # compute gradients\n",
        "\n",
        "    opt.step() # apply gradients\n",
        "\n",
        "    print(f'epoch {epoch}: loss is {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy\n",
        "y_pred = linear_model(X)\n",
        "num_pred = y_pred.size(dim=0)\n",
        "max_val, max_idx = torch.max(y_pred, dim = 1)\n",
        "\n",
        "total = 0\n",
        "# iterate through the tensor, look to see if the y_pred matched the value of the actual y\n",
        "# print(max_idx)\n",
        "for i in range(num_pred):\n",
        "  if max_idx[i] == y[i]:\n",
        "    total += 1\n",
        "\n",
        "accuracy = total/num_pred\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "jj4G4ky8WJ8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs3zedgwNjBC"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "Extend the above code to implement an MLP with a single hidden layer of size 100.\n",
        "\n",
        "Write code to compute the accuracy of each model.\n",
        "\n",
        "Can you get the MLP to outperform the linear model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko-8MSgDNjBC"
      },
      "outputs": [],
      "source": [
        "multilayer_model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2,100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100,3),\n",
        "    # two inputs, three outputs\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.SGD(multilayer_model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    opt.zero_grad() # zero out the gradients\n",
        "\n",
        "    z = multilayer_model(X) # compute z values\n",
        "    loss = loss_fn(z,y) # compute loss\n",
        "\n",
        "    loss.backward() # compute gradients\n",
        "\n",
        "    opt.step() # apply gradients\n",
        "\n",
        "    print(f'epoch {epoch}: loss is {loss.item()}')"
      ],
      "metadata": {
        "id": "2Test8htRE60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy\n",
        "y_pred = multilayer_model(X)\n",
        "num_pred = y_pred.size(dim=0)\n",
        "max_val, max_idx = torch.max(y_pred, dim = 1)\n",
        "\n",
        "total = 0\n",
        "# iterate through the tensor, look to see if the y_pred matched the value of the actual y\n",
        "#print(max_idx)\n",
        "for i in range(num_pred):\n",
        "  if max_idx[i] == y[i]:\n",
        "    total += 1\n",
        "\n",
        "accuracy = total/num_pred\n",
        "print(accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "K0p46BqlSecv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}