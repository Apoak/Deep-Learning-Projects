{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoak/Deep-Learning-Projects/blob/main/Facial_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OUW75f1w56j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import sklearn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNAG8fBHw_ns",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('facial_keypoints.npz'):\n",
        "  !wget -O facial_keypoints.npz \"https://www.dropbox.com/scl/fi/27qggijmythfjg04s24xq/facial_keypoints.npz?rlkey=h91gwodhrfuz8hrc7ux9qnq7s&dl=1\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking out the data**"
      ],
      "metadata": {
        "id": "ExuOc3-EKhR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ItzVkCnCaYrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSnb9owtxT5w"
      },
      "outputs": [],
      "source": [
        "data = np.load('facial_keypoints.npz')\n",
        "base_images = data['images']\n",
        "base_keypoints = data['keypoints']\n",
        "print(base_images.shape)\n",
        "print(base_keypoints.shape)\n",
        "print(base_images[12])\n",
        "# print(images[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(base_images[i].squeeze(), cmap='gray')  # Display the image in grayscale\n",
        "    ax.scatter(base_keypoints[i][0::2], base_keypoints[i][1::2], s=5, marker='.', c='m')  # Display keypoints\n",
        "    ax.axis('off')  # Hide axes\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g5dGSy6NsmzX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the data:**"
      ],
      "metadata": {
        "id": "zxoG2J90Klww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before min max\n",
        "print(f\"Keypoints: {base_keypoints.shape}, {base_keypoints.dtype}, {np.nanmin(data['keypoints'])},  {np.nanmax(data['keypoints'])}\")\n",
        "print(f\"Images: {base_images.shape}, {base_images.dtype}, {np.min(data['images'])},  {np.max(data['images'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFdETE8UDx7f",
        "outputId": "e112ba66-ac6a-4ee4-db9d-5e78f294c621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints: (7049, 30), float32, 0.6865919828414917,  95.9356460571289\n",
            "Images: (7049, 1, 96, 96), int64, 0,  255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Citation\n",
        "min_max_scaler = sklearn.preprocessing.MinMaxScaler((0,96))\n",
        "images_reshaped = base_images.reshape(7049, -1)\n",
        "images_scaled = min_max_scaler.fit_transform(images_reshaped)\n",
        "images_scaled = images_scaled.reshape(7049, 1, 96, 96)\n",
        "\n",
        "# keypoints = min_max_scaler.fit_transform(keypoints.reshape(-1, 30)).reshape(-1, 15, 2)\n",
        "\n",
        "#keypoints_scaled = min_max_scaler.fit_transform(base_keypoints.reshape(-1, 30)).reshape(-1, 30)\n",
        "\n",
        "# print(f\"Scaled Keypoints: {keypoints.shape}, {keypoints.dtype}, {np.nanmin(keypoints)},  {np.nanmax(keypoints_s)}\")\n",
        "print(f\"Scaled Images: {images_scaled.shape}, {images_scaled.dtype}, {np.min(images_scaled)},  {np.max(images_scaled)}\")\n"
      ],
      "metadata": {
        "id": "qTxipq0QIdg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and test split:**"
      ],
      "metadata": {
        "id": "8Y2sK69bKqw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TUZkzVGpOMAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(images_scaled).float().cuda()\n",
        "y = torch.tensor(base_keypoints).float().cuda()\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)",

        "print(X_train.dtype)\n",
        "# print(y_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(y_test.shape)"
      ],
      "metadata": {
        "id": "8aJbjG7gNw7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the data loader:**"
      ],
      "metadata": {
        "id": "T1Trek0qOTeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "batch_size = 32 # Think about this one!\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "AyC1aeUCOS9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "batch_size = 32 # Think about this one!\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "LmfFDLzTO3xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a CNN:**"
      ],
      "metadata": {
        "id": "suNRb2mQSUVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "G2AIweKlXlFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Citation:** Looked at this for some guidance https://www.digitalocean.com/community/tutorials/vgg-from-scratch-pytorch"
      ],
      "metadata": {
        "id": "i1QayhabQ3kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cnn(nn.Module):\n",
        "    def __init__(self, num_classes = 30):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding = 1),\n",
        "            nn.ReLU())\n",
        "        # Pools\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 4, 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)) # 96/2 = 48\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding = 1),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Pools\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(8, 8, 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)) # 48/2 = 24\n",
        "\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 3, padding = 1),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Pools and Flattens\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), #24/2 = 12\n",
        "            torch.nn.Flatten())\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(12*12*16, 4096),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Output\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        # print(f\"layer1 shape: {out.shape}\")\n",
        "        out = self.layer2(out)\n",
        "        # print(f\"layer2 shape: {out.shape}\")\n",
        "        out = self.layer3(out)\n",
        "        # print(f\"layer3 shape: {out.shape}\")\n",
        "        out = self.layer4(out)\n",
        "        # print(f\"layer4 shape: {out.shape}\")\n",
        "        out = self.layer5(out)\n",
        "        # print(f\"layer5 shape: {out.shape}\")\n",
        "        out = self.layer6(out)\n",
        "        # print(f\"layer6/flatten shape : {out.shape}\")\n",
        "        out = self.fc(out)\n",
        "        # print(f\"Dense1 shape: {out.shape}\")\n",
        "        out = self.fc1(out)\n",
        "        # print(f\"Dense2 shape: {out.shape}\")\n",
        "        out = self.fc2(out)\n",
        "        # print(f\"Output shape: {out.shape}\")\n",
        "        return out\n",
        "\n",
        "cnn = Cnn().cuda()\n",
        "# # Debug\n",
        "# x, y = next(iter(train_loader))\n",
        "# #print(x.shape)\n",
        "# print(cnn(x.cuda()).shape)\n",
        "# print(cnn(x.cuda()))\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FxSMFoq5SbFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_mae_loss(y_pred,y_true):\n",
        "    y_true = y_true.cuda()\n",
        "\n",
        "    mask = 1-torch.isnan(y_true).float()\n",
        "\n",
        "    diff = torch.abs(y_true-y_pred)\n",
        "\n",
        "    return torch.nansum(diff*mask)/torch.nansum(mask)"
      ],
      "metadata": {
        "id": "XnP9aQO5LHNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Citation:** Used chatGPT to help me deal with the nan values in the y_true."
      ],
      "metadata": {
        "id": "iERyruo5HmtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are custom mean absolute error and mean squared error functions which deal with the nan values in the y_true.\n",
        "def masked_mae(y_pred, y_true):\n",
        "    mask = ~torch.isnan(y_true)\n",
        "    if mask.sum() == 0:\n",
        "        return torch.tensor(0.0, device=y_pred.device)  # No valid data\n",
        "    return torch.mean(torch.abs(y_pred[mask] - y_true[mask]))\n",
        "\n",
        "def masked_mse(y_pred, y_true):\n",
        "    mask = ~torch.isnan(y_true)\n",
        "    if mask.sum() == 0:\n",
        "        return torch.tensor(0.0, device=y_pred.device)\n",
        "    return torch.mean((y_pred[mask] - y_true[mask])**2)\n"
      ],
      "metadata": {
        "id": "-zgiAQs_Fivc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "def masked_r2(y_pred, y_true):\n",
        "    y_pred_np = y_pred.cpu().detach().numpy()\n",
        "    y_true_np = y_true.cpu().detach().numpy()\n",
        "\n",
        "    valid_mask = ~np.isnan(y_true_np)  # Ignore NaNs\n",
        "    if np.sum(valid_mask) == 0:\n",
        "        return np.nan  # No valid values\n",
        "\n",
        "    return r2_score(y_true_np[valid_mask], y_pred_np[valid_mask])\n"
      ],
      "metadata": {
        "id": "7bClCx0gFvKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test cnn\n",
        "def test_cnn(cnn, test_loader):\n",
        "    # cnn.eval()\n",
        "  mae_total, mse_total = 0, 0\n",
        "  count = 0\n",
        "\n",
        "  for x_batch, y_true in test_loader:\n",
        "    x_batch = x_batch.cuda()\n",
        "    y_true = y_true.cuda()\n",
        "    y_pred = cnn(x_batch.cuda())\n",
        "\n",
        "    mae_total += masked_mae(y_pred, y_true)\n",
        "    mse_total += masked_mse(y_pred, y_true)\n",
        "    count += 1\n",
        "\n",
        "  print(\"Final MAE:\", mae_total / count)\n",
        "  print(\"Final MSE:\", mse_total / count)\n",
        "  print(\"Final RÂ² Score:\", masked_r2(y_pred, y_true.cuda()))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KIcqwQlaMWg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the model before training**"
      ],
      "metadata": {
        "id": "oGyxw-PcGn4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn(cnn, test_loader)"
      ],
      "metadata": {
        "id": "cGhkxH3wGiJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train cnn\n",
        "def train_cnn(cnn, train_loader, epochs, optimizer):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "      x_batch = x_batch.cuda()\n",
        "      y_batch = y_batch.cuda()\n",
        "      # cnn.forward(x_batch)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = cnn.forward(x_batch.float())\n",
        "      # print(f\"y_pred shape: {y_pred.shape}, y_batch shape: {y_batch.shape}\")\n",
        "      loss = masked_mae_loss(y_pred,y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DT8J_u1rKSf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cnn(cnn, train_loader, epochs=70, optimizer = torch.optim.SGD(cnn.parameters(),lr=0.0003))"
      ],
      "metadata": {
        "id": "locd0-PAG5IB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the model after training**"
      ],
      "metadata": {
        "id": "665PtfdgHV1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn(cnn, test_loader)"
      ],
      "metadata": {
        "id": "Xe_dmSej-ild"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test images with Ground truth keypoints**\n",
        "Truth values: Pink\n",
        "Predicted: Blue\n"
      ],
      "metadata": {
        "id": "v1n2s3q0HbwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "dataiter = iter(test_loader)\n",
        "test_images, test_labels = next(dataiter)\n",
        "pred_labels = cnn(test_images.cuda())\n",
        "\n",
        "pred_labels = pred_labels.cpu()\n",
        "pred_labels = pred_labels.detach().numpy()\n",
        "#print(test_labels)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(test_images[i].cpu().squeeze(), cmap='gray')  # Display the image in grayscale\n",
        "    ax.scatter(test_labels[i][0::2].cpu(), (test_labels[i][1::2].cpu()), s=20, marker='.', c='m')  # Display keypoints\n",
        "    ax.scatter(pred_labels[i][0::2], (pred_labels[i][1::2]), s=20, marker='.', c='b')  # Display keypoints\n",
        "    ax.axis('off')  # Hide axes\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pk7VvL2fSLRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicted keypoints over Training Images:**\n",
        "Truth Values: Pink\n",
        "Predicted values: Blue"
      ],
      "metadata": {
        "id": "m2hNbbpNesYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "dataiter = iter(train_loader)\n",
        "train_images, truth_labels = next(dataiter)\n",
        "\n",
        "train_labels = cnn(train_images[:32].cuda())\n",
        "train_labels = train_labels.cpu()\n",
        "train_labels = train_labels.detach().numpy()\n",
        "\n",
        "train_labels = train_labels\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # print(labels[i])\n",
        "    ax.imshow(train_images[i][0].cpu(), cmap='gray')  # Display the image in grayscale\n",
        "    ax.scatter(truth_labels[i][0::2].cpu(), (truth_labels[i][1::2].cpu()), s=20, marker='.', c='m')  # Display keypoints\n",
        "    ax.scatter(train_labels[i][0::2], (train_labels[i][1::2]), s=20, marker='.', c='b')  # Display keypoints\n",
        "    ax.axis('off')  # Hide axes\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qctTVZvteapq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis:**\n",
        "While the MAE and MSE are not large values and the R^2 is good, when the predicted keypoints are projected onto a test or training image it is obvious that small difference in ground truth pixel values and prodicted pixel values result in keypoints looking visually incorrect.\n",
        "\n",
        "The network seems to be able to identify keypoints around the eyes much better than keypoints around the mouth.\n",
        "\n",
        "In regards to overfitting it appears the network is better at outputting keypoints on training images than on testing images. This is reflected in the various image grids above.\n",
        "\n",
        "The model seems to have a higher level of variance."
      ],
      "metadata": {
        "id": "ZfGqcNWMZLwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improved CNN:**\n",
        "Added dropout and batch normalization"
      ],
      "metadata": {
        "id": "xC89lWUP-Bgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Improved_Cnn(nn.Module):\n",
        "    def __init__(self, num_classes = 30):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 4, 3, padding = 1),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.ReLU())\n",
        "        # Pools\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(4, 4, 3, padding = 1),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)) # 96/2 = 48\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding = 1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Pools\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(8, 8, 3, padding = 1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)) # 48/2 = 24\n",
        "\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 3, padding = 1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Pools and Flattens\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding = 1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), #24/2 = 12\n",
        "            torch.nn.Flatten())\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(.2),\n",
        "            nn.Linear(12*12*16, 4096),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(.2),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # Output\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        # print(f\"Output shape: {out.shape}\")\n",
        "        return out\n",
        "\n",
        "improved_cnn = Improved_Cnn().cuda()\n",
        "# # Debug\n",
        "# x, y = next(iter(train_loader))\n",
        "# #print(x.shape)\n",
        "# print(cnn(x.cuda()).shape)\n",
        "# print(cnn(x.cuda()))\n",
        "\n"
      ],
      "metadata": {
        "id": "pNlyLDxLEamQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test before training:**"
      ],
      "metadata": {
        "id": "J2gMTfeVFnLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn(improved_cnn, test_loader)"
      ],
      "metadata": {
        "id": "5OCS2QbsFaOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train improved cnn:**"
      ],
      "metadata": {
        "id": "-1-BDJlAFo5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_cnn(improved_cnn, train_loader, epochs=130, optimizer = torch.optim.Adam(cnn.parameters(),lr=0.0003, weight_decay= .001))"
      ],
      "metadata": {
        "id": "DO_RjVEtFpOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test improved cnn after training:**"
      ],
      "metadata": {
        "id": "0zCRbbgpF9_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn(improved_cnn, test_loader)"
      ],
      "metadata": {
        "id": "Ktz9xS1jGDra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test images with predicted keypoints:**\n",
        "Pink: Truth\n",
        "Blue: Predicted"
      ],
      "metadata": {
        "id": "q8jxeFk9GNFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "dataiter = iter(test_loader)\n",
        "test_images2, test_labels2 = next(dataiter)\n",
        "pred_labels2 = cnn(test_images.cuda())\n",
        "\n",
        "pred_labels2 = pred_labels2.cpu()\n",
        "pred_labels2 = pred_labels2.detach().numpy()\n",
        "#print(test_labels)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(test_images2[i].cpu().squeeze(), cmap='gray')  # Display the image in grayscale\n",
        "    ax.scatter(test_labels2[i][0::2].cpu(), (test_labels2[i][1::2].cpu()), s=20, marker='.', c='m')  # Display keypoints\n",
        "    ax.scatter(pred_labels2[i][0::2], (pred_labels2[i][1::2]), s=20, marker='.', c='b')  # Display keypoints\n",
        "    ax.axis('off')  # Hide axes\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nMiOFhijGO63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**predicted keypoints over training images:**\n",
        "Truth: Pink\n",
        "Predicted: blue"
      ],
      "metadata": {
        "id": "3_7NT0b-4J7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "dataiter = iter(train_loader)\n",
        "train_images2, truth_labels2 = next(dataiter)\n",
        "\n",
        "train_labels2 = cnn(train_images2[:32].cuda())\n",
        "train_labels2 = train_labels2.cpu()\n",
        "train_labels2 = train_labels2.detach().numpy()\n",
        "\n",
        "train_labels = train_labels\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # print(labels[i])\n",
        "    ax.imshow(train_images2[i][0].cpu(), cmap='gray')  # Display the image in grayscale\n",
        "    ax.scatter(truth_labels2[i][0::2].cpu(), (truth_labels2[i][1::2].cpu()), s=20, marker='.', c='m')  # Display keypoints\n",
        "    ax.scatter(train_labels2[i][0::2], (train_labels2[i][1::2]), s=20, marker='.', c='b')  # Display keypoints\n",
        "    ax.axis('off')  # Hide axes\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rGBtryzA3O-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7_8gTtzQINMK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
